---
title: Overview
description: "AI-native incident management that investigates outages, not just alerts you"
icon: triangle-exclamation
---

**Incident response should be about solving problems, not finding them.**

Your monitoring tools are excellent at detection—they catch anomalies in milliseconds and route alerts to the right engineer. But when an alert fires at 3 AM, you still need to pull up six dashboards, correlate timestamps across services, check recent deployments, and piece together the story yourself.

CloudThinker Incidents is different. When an incident occurs, an AI agent begins investigating immediately—forming hypotheses, gathering evidence, and identifying root causes the way an experienced engineer would. By the time you open your laptop, the investigation is already underway.

<Frame>
  <img src="/images/incidents/overview/01-incident-dashboard-rca.jpg" alt="Incident Response dashboard displaying a critical incident with root cause analysis findings, affected services topology, and prioritized remediation suggestions" />
</Frame>
<p style={{textAlign: 'center', fontSize: '0.9em', color: '#666', marginTop: '8px'}}>CloudThinker Incidents dashboard showing AI-powered root cause analysis in action</p>

---

## AI That Investigates

CloudThinker Incidents is AI-native. The AI isn't a chatbot bolted onto an existing product—it's the foundation of how incidents are analyzed and resolved.

<CardGroup cols={2}>
  <Card title="Hypothesis-Driven Investigation" icon="brain">
    The AI forms theories about what went wrong and systematically tests each one against your data, tracking which hypotheses are confirmed or ruled out.
  </Card>
  <Card title="Transparent Reasoning" icon="eye">
    Every step is visible in real-time. See what the AI checked, what it found, and the path it took to reach its conclusion. No black box.
  </Card>
  <Card title="Structured Evidence" icon="layer-group">
    Metrics with before/after comparisons, logs with timestamps, deployment changes with time-to-incident calculations—all organized into a coherent chain.
  </Card>
  <Card title="Confidence Scoring" icon="chart-simple">
    Not every investigation reaches certainty. Confidence scores tell you whether you're looking at a definitive answer or a hypothesis that needs verification.
  </Card>
</CardGroup>

---

## How It Works

<Steps>
  <Step title="Incident Created">
    An incident is created manually, via API, or automatically when webhook alerts arrive from your monitoring tools.
  </Step>
  <Step title="Investigation Begins">
    An AI agent immediately starts investigating—no waiting, no manual trigger required.
  </Step>
  <Step title="Hypotheses Tested">
    The agent forms theories ("memory leak in auth service", "recent deployment regression", "exhausted connection pool") and tests each one.
  </Step>
  <Step title="Evidence Gathered">
    Metrics, logs, traces, configurations, and deployments are collected and organized with timeline correlation.
  </Step>
  <Step title="Root Cause Identified">
    The AI identifies the root cause with confidence scoring and transparent reasoning you can verify.
  </Step>
  <Step title="Remediation Suggested">
    Prioritized action steps are generated—from critical fixes to improvements—ready for your team to execute.
  </Step>
</Steps>

---

## Topology Awareness

Your services don't exist in isolation. When your auth service fails, everything downstream fails too—checkout breaks, mobile apps throw errors, and support tickets spike across seemingly unrelated features.

CloudThinker understands your infrastructure topology. When an incident occurs, the AI automatically:

- **Identifies affected services** using your service dependency map
- **Calculates blast radius** showing what's broken and what's impacted
- **Investigates with context** knowing that payment depends on auth, which depends on Redis, which runs on a specific cluster

You see affected services visualized in real-time, with severity-coded nodes showing the spread of impact across your infrastructure.

---

## Connect Everything You Already Use

CloudThinker integrates with the monitoring tools your team already relies on. We support webhooks from **15+ platforms**:

| Platform | What's Supported |
|----------|------------------|
| **PagerDuty** | Native field mapping for alert details and priorities |
| **Datadog** | Metrics, alerts, and event correlation |
| **Prometheus / Alertmanager** | Kubernetes-native monitoring |
| **AWS CloudWatch** | Native support for AWS infrastructure alerts |
| **Opsgenie** | Priority and description extraction |
| **New Relic, Grafana, Splunk, Dynatrace, Sentry** | And more |

Each integration includes platform-specific field mapping—incident titles, descriptions, and severity levels are extracted correctly without manual configuration.

---

## Continuous Learning

Every incident is an opportunity to get better. CloudThinker's agent memory system captures investigation patterns so the AI improves over time.

When the agent discovers that a particular metric query is useful for diagnosing memory issues, or that a specific log pattern indicates a connection pool problem, those techniques become part of its toolkit. Your team's operational knowledge—the hard-won insights from years of debugging production systems—gets preserved and applied automatically.

---

## Next Steps

Ready to start investigating incidents? Set up incident ingestion from your monitoring tools:

<Card title="Webhook Integrations" icon="webhook" href="/guide/incident/webhook-integrations">
  Connect your monitoring platforms to auto-create incidents. Configure field mappings for PagerDuty, Datadog, Prometheus, CloudWatch, and 10+ more platforms.
</Card>

Once incidents are flowing in, explore the [Root Cause Analysis](/guide/incident/root-cause-analysis) workflow to understand how AI agents investigate and prioritize remediation steps.

